title: "Release v0.1.0-gliner"
description: |
  This is a spaCy project that trains and evaluates new v0.1.0-gliner models.
  [GliNER](https://github.com/urchade/GLiNER) (Generalist and Lightweight Model for Named Entity Recognition) is a powerful model capable of identifying any entity type using a BERT-like encoder.
  In this project, we finetune the GliNER model using the TLUnified-NER dataset.

  To replicate training, first you need to install the required dependencies:

  ```sh
  pip install -r requirements.txt
  ```

  ## Training

  To train a GliNER model, run the `finetune-gliner` workflow while passing the size:

  ```sh
  # Available options: 'small', 'medium', 'large'
  python -m spacy project run finetune-gliner . --vars.size small
  ```

  The models are currently based on the [v2.5 version of GliNER](https://huggingface.co/collections/urchade/gliner-v25-66743e64ab975c859119d1eb).

  ## Evaluation

  To perform evals, run the `eval-gliner` workflow while passing the size:

  ```sh
  # Available options: 'small', 'medium', 'large'
  python -m spacy project run eval-gliner . --vars.size small
  ```

  This will evaluate on TLUnified-NER's test set ([Miranda, 2023](https://aclanthology.org/2023.sealp-1.2.pdf)) and the Tagalog subsets of
  Universal NER ([Mayhew et al., 2024](https://aclanthology.org/2024.naacl-long.243/)).

  The evaluation results for TLUnified-NER are shown in the table below (reported numbers are F1-scores):

  |                  | PER   | ORG   | LOC   | Overall |
  |------------------|-------|-------|-------|---------|
  | [tl_gliner_small](https://huggingface.co/ljvmiranda921/tl_gliner_small)  | 86.76 | 78.72 | 86.78 | 84.83   |
  | [tl_gliner_medium](https://huggingface.co/ljvmiranda921/tl_gliner_medium) | 87.46 | 79.71 | 86.75 | 85.40   |
  | [tl_gliner_large](https://huggingface.co/ljvmiranda921/tl_gliner_large)  | 86.75 | 80.20 | 86.76 | 85.72   |
  | [tl_calamancy_trf](https://huggingface.co/ljvmiranda921/tl_calamancy_trf) | 91.95 | **84.84** | 88.92 | 88.03   |
  | [span-marker](https://huggingface.co/tomaarsen/span-marker-roberta-tagalog-base-tlunified)      | **92.57** | 82.04 | **90.56** | **89.62**   |

  In general, GliNER gets decent scores, but nothing beats regular finetuning on BERT-based models as seen in [tl_calamancy_trf](https://huggingface.co/ljvmiranda921/tl_calamancy_trf) and [span_marker](https://huggingface.co/tomaarsen/span-marker-roberta-tagalog-base-tlunified).
  The performance on Universal NER is generally worse (the highest is around ~50%), compared to the reported results in the Universal NER paper (we finetuned on RoBERTa as well).
  One possible reason is that the annotation guidelines for TULunified-NER are more loose, because we consider some entities that Universal NER ignores.
  At the same time, the text distribution of the two datasets are widely different.

  Nevertheless, I'm still releasing these GliNER models as they are very extensible to other entity types (and it's also nice to have a finetuned version of GliNER for Tagalog!).
  I haven't done any extensive hyperparameter tuning here so it might be nice if someone can contribute better config parameters to bump up these scores.

vars:
  version: 0.1.0
  # Training
  size: small
  num_steps: 10000
  batch_size: 8

directories:
  - "checkpoints"
  - "models"
  - "metrics"

env:
  HF_TOKEN: HF_TOKEN
  TOKENIZERS_PARALLELISM: TOKENIZERS_PARALLELISM

commands:
  - name: "finetune-gliner"
    help: "Finetune the GliNER model using TLUnified-NER"
    script:
      - mkdir -p models/gliner_${vars.size}
      - mkdir -p checkpoints/ckpt_gliner_${vars.size}
      - >-
        python train.py 
          gliner-community/gliner_${vars.size}-v2.5
          models/gliner_${vars.size}
          --checkpoint-dir checkpoints/ckpt_gliner_${vars.size}
          --push-to-hub ljvmiranda921/tl_gliner_${vars.size}
          --num-steps ${vars.num_steps}
          --batch-size ${vars.batch_size}
          --dataset ljvmiranda921/tlunified-ner
    outputs:
      - models/gliner_${vars.size}
      - checkpoints/ckpt_gliner_${vars.size}

  - name: "eval-gliner"
    help: "Evaluate trained GliNER models on the TLUnified-NER and Universal NER test sets"
    script:
      # TLUnified-NER
      - >-
        python evaluate.py
          metrics/model___tl_gliner_${vars.size}_dataset___ljvmiranda921-tlunified-ner.json
          --model-name ljvmiranda921/tl_gliner_${vars.size}
          --dataset ljvmiranda921/tlunified-ner
          --label-map person::PER,location::LOC,organization::ORG
      # Universal NER (tl_trg)
      - >-
        python evaluate.py
          metrics/model___tl_gliner_${vars.size}_dataset___universalner-universal_ner.json
          --model-name ljvmiranda921/tl_gliner_${vars.size}
          --dataset universalner/universal_ner
          --dataset-config tl_trg
          --label-map person::PER,location::LOC,organization::ORG
      # Universal NER (tl_ugnayan)
      - >-
        python evaluate.py
          metrics/model___tl_gliner_${vars.size}_dataset___universalner-universal_ner.json
          --model-name ljvmiranda921/tl_gliner_${vars.size}
          --dataset universalner/universal_ner
          --dataset-config tl_ugnayan
          --label-map person::PER,location::LOC,organization::ORG
